{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "# ================\n",
    "\n",
    "# for date and time opeations\n",
    "from datetime import datetime\n",
    "# for file and folder operations\n",
    "import os\n",
    "# for regular expression opeations\n",
    "import re\n",
    "# for listing files in a folder\n",
    "import glob\n",
    "# for getting web contents\n",
    "import requests \n",
    "# storing and analysing data\n",
    "import pandas as pd\n",
    "# for scraping web contents\n",
    "from bs4 import BeautifulSoup\n",
    "# regular expression\n",
    "import re\n",
    "# for numerical analysis\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "# ========\n",
    "\n",
    "# link at which web data recides\n",
    "link = 'https://www.mohfw.gov.in/'\n",
    "# get web data\n",
    "req = requests.get(link)\n",
    "# parse web data\n",
    "soup = BeautifulSoup(req.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-eda41c6e195c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# get the table tbody\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# it contains the contents\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mtbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tbody'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;31m# print(tbody)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# find the table\n",
    "# ==============\n",
    "# our target table is the last table in the page\n",
    "\n",
    "# get the table head\n",
    "# table head may contain the column names, titles, subtitles\n",
    "thead = soup.find_all('thead')[-1]\n",
    "# print(thead)\n",
    "\n",
    "# get all the rows in table head\n",
    "# it usually have only one row, which has the column names\n",
    "head = thead.find_all('tr')\n",
    "# print(head)\n",
    "\n",
    "# get the table tbody\n",
    "# it contains the contents\n",
    "tbody = soup.find_all('tbody')[-1]\n",
    "# print(tbody)\n",
    "\n",
    "# get all the rows in table body\n",
    "# each row is each state's entry\n",
    "body = tbody.find_all('tr')\n",
    "# print(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the table contents\n",
    "# ======================\n",
    "\n",
    "# container for header rows / column title\n",
    "head_rows = []\n",
    "# container for table body / contents\n",
    "body_rows = []\n",
    "\n",
    "# loop through the head and append each row to head\n",
    "for tr in head:\n",
    "    td = tr.find_all(['th', 'td'])\n",
    "    row = [i.text for i in td]\n",
    "    head_rows.append(row)\n",
    "# print(head_rows)\n",
    "\n",
    "# loop through the body and append each row to body\n",
    "for tr in body:\n",
    "    td = tr.find_all(['th', 'td'])\n",
    "    row = [i.text for i in td]\n",
    "    body_rows.append(row)\n",
    "# print(head_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save contents in a dataframe\n",
    "# ============================\n",
    "    \n",
    "# skip last 3 rows, it contains unwanted info\n",
    "# head_rows contains column title\n",
    "df_bs = pd.DataFrame(body_rows[:len(body_rows)-6], \n",
    "                     columns=head_rows[0])         \n",
    "\n",
    "# Drop 'S. No.' column\n",
    "df_bs.drop('S. No.', axis=1, inplace=True)\n",
    "\n",
    "# there are 36 states+UT in India\n",
    "df_bs.head(36)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date-time information\n",
    "# =====================\n",
    "\n",
    "# today's date\n",
    "now  = datetime.now()\n",
    "# format date to month-day-year\n",
    "df_bs['Date'] = now.strftime(\"%m/%d/%Y\") \n",
    "\n",
    "# add 'Date' column to dataframe\n",
    "df_bs['Date'] = pd.to_datetime(df_bs['Date'], format='%m/%d/%Y')\n",
    "\n",
    "# df_bs.head(36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove extra characters from 'Name of State/UT' column\n",
    "df_bs['Name of State / UT'] = df_bs['Name of State / UT'].str.replace('#', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latitude and longitude information\n",
    "# ==================================\n",
    "\n",
    "# latitude of the states\n",
    "lat = {'Delhi':28.7041, 'Haryana':29.0588, 'Kerala':10.8505, 'Rajasthan':27.0238,\n",
    "       'Telengana':18.1124, 'Telangana':18.1124, 'Uttar Pradesh':26.8467, 'Ladakh':34.2996, 'Tamil Nadu':11.1271,\n",
    "       'Jammu and Kashmir':33.7782, 'Punjab':31.1471, 'Karnataka':15.3173, 'Maharashtra':19.7515,\n",
    "       'Andhra Pradesh':15.9129, 'Odisha':20.9517, 'Uttarakhand':30.0668, 'West Bengal':22.9868, \n",
    "       'Puducherry': 11.9416, 'Chandigarh': 30.7333, 'Chhattisgarh':21.2787, 'Gujarat': 22.2587, \n",
    "       'Himachal Pradesh': 31.1048, 'Madhya Pradesh': 22.9734, 'Bihar': 25.0961, 'Manipur':24.6637, \n",
    "       'Mizoram':23.1645, 'Goa': 15.2993, 'Andaman and Nicobar Islands': 11.7401, 'Assam' : 26.2006, \n",
    "       'Jharkhand': 23.6102, 'Arunachal Pradesh': 28.2180, 'Tripura': 23.9408, 'Nagaland': 26.1584, \n",
    "       'Meghalaya' : 25.4670, 'Dadar Nagar Haveli' : 20.1809, 'Sikkim':27.5330, \n",
    "       'Dadra and Nagar Haveli and Daman and Diu': 20.1809}\n",
    "\n",
    "# longitude of the states\n",
    "long = {'Delhi':77.1025, 'Haryana':76.0856, 'Kerala':76.2711, 'Rajasthan':74.2179,\n",
    "        'Telengana':79.0193, 'Telangana':79.0193, 'Uttar Pradesh':80.9462, 'Ladakh':78.2932, 'Tamil Nadu':78.6569,\n",
    "        'Jammu and Kashmir':76.5762, 'Punjab':75.3412, 'Karnataka':75.7139, 'Maharashtra':75.7139,\n",
    "        'Andhra Pradesh':79.7400, 'Odisha':85.0985, 'Uttarakhand':79.0193, 'West Bengal':87.8550, \n",
    "        'Puducherry': 79.8083, 'Chandigarh': 76.7794, 'Chhattisgarh':81.8661, 'Gujarat': 71.1924, \n",
    "        'Himachal Pradesh': 77.1734, 'Madhya Pradesh': 78.6569, 'Bihar': 85.3131, 'Manipur':93.9063, \n",
    "        'Mizoram':92.9376, 'Goa': 74.1240, 'Andaman and Nicobar Islands': 92.6586, 'Assam' : 92.9376, \n",
    "        'Jharkhand': 85.2799, 'Arunachal Pradesh': 94.7278, 'Tripura': 91.9882, 'Nagaland': 94.5624,\n",
    "        'Meghalaya' : 91.3662, 'Dadar Nagar Haveli' : 73.0169, 'Sikkim':88.5122,\n",
    "        'Dadra and Nagar Haveli and Daman and Diu': 73.0169}\n",
    "\n",
    "# add latitude column based on 'Name of State / UT' column\n",
    "df_bs['Latitude'] = df_bs['Name of State / UT'].map(lat)\n",
    "\n",
    "# add longitude column based on 'Name of State / UT' column\n",
    "df_bs['Longitude'] = df_bs['Name of State / UT'].map(long)\n",
    "\n",
    "# df_bs.head(36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# unique state names\n",
    "df_bs['Name of State / UT'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of missing values \n",
    "df_bs.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# number of unique values \n",
    "df_bs.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# saving data\n",
    "# ===========\n",
    "\n",
    "# file names as year-month-day.csv format\n",
    "file_name = now.strftime(\"%Y_%m_%d\")+'.csv'\n",
    "\n",
    "# location for saving the file\n",
    "file_loc = 'C:\\\\Users\\\\imdevskp\\\\Documents\\\\github\\\\covid_india\\\\.day_by_day_data\\\\'\n",
    "\n",
    "# save file as a scv file\n",
    "df_bs.to_csv(file_loc + file_name, index=False)\n",
    "\n",
    "df_bs.head(36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column names \n",
    "# df_bs.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all files available\n",
    "# ! ls C:\\Users\\imdevskp\\Documents\\github\\covid_india\\.day_by_day_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of the file\n",
    "loc = \"C:\\\\Users\\\\imdevskp\\\\Documents\\\\github\\\\covid_india\\\\.day_by_day_data\\\\\"\n",
    "\n",
    "# list of all files\n",
    "files = glob.glob(loc+'2020*.csv')\n",
    "   \n",
    "# container for each day's data's dataframe\n",
    "dfs = []\n",
    "\n",
    "# loop through the files and append to the dfs list\n",
    "for i in files:\n",
    "    # read data\n",
    "    df_temp = pd.read_csv(i)\n",
    "    \n",
    "    # rename columns\n",
    "    \n",
    "    try:\n",
    "        df_temp = df_temp.drop(['Total Confirmed cases (Indian National)', \n",
    "                                'Total Confirmed cases ( Foreign National )'], axis=1)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    d = {'^Cured.*': 'Cured/Discharged/Migrated', \n",
    "         'Total Confirmed cases.*': 'Total Confirmed cases', \n",
    "         'Death.*': 'Death'}\n",
    "    \n",
    "    df_temp.columns = df_temp.columns.to_series().replace(d, regex=True)\n",
    "\n",
    "\n",
    "#     df_temp = df_temp.rename(columns={'Cured':'Cured/Discharged'})\n",
    "#     df_temp = df_temp.rename(columns={'Cured/Discharged':'Cured/Discharged/Migrated', \n",
    "#                                       'Total Confirmed cases *': 'Total Confirmed cases', \n",
    "#                                       'Total Confirmed cases ': 'Total Confirmed cases', \n",
    "#                                       'Total Confirmed cases* ': 'Total Confirmed cases'})\n",
    "#     df_temp = df_temp.rename(columns=lambda x: re.sub('Total Confirmed cases \\(Including .* foreign Nationals\\) ',\n",
    "#                                                       'Total Confirmed cases',x))\n",
    "#     df_temp = df_temp.rename(columns=lambda x: re.sub(\"Death.*\", \"Death\", x))\n",
    "\n",
    "    \n",
    "    # append to the df_s\n",
    "    dfs.append(df_temp)\n",
    "    \n",
    "# print(dfs)\n",
    "\n",
    "# concat dataframes\n",
    "complete_data = pd.concat(dfs, ignore_index=True).sort_values(['Date'], ascending=True).reset_index(drop=True)\n",
    "\n",
    "# get just numbers\n",
    "complete_data['Death'] = complete_data['Death'].astype('str').str.extract('(\\d+)').astype('int')\n",
    "\n",
    "# few sample rows\n",
    "complete_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix datatype\n",
    "complete_data['Date'] = pd.to_datetime(complete_data['Date'])\n",
    "\n",
    "# sort rows\n",
    "complete_data = complete_data.sort_values(['Date', 'Name of State / UT']).reset_index(drop=True)\n",
    "\n",
    "# fill missing values with 0\n",
    "cols = ['Cured/Discharged/Migrated', 'Death']\n",
    "complete_data[cols] = complete_data[cols].fillna(0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename state/UT names\n",
    "complete_data['Name of State / UT'].replace('Chattisgarh', 'Chhattisgarh', inplace=True)\n",
    "complete_data['Name of State / UT'].replace('Pondicherry', 'Puducherry', inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only rows with more than 1 case\n",
    "complete_data = complete_data[complete_data['Total Confirmed cases']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop extra columns\n",
    "complete_data = complete_data.drop(['Active Cases*'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearrange columns\n",
    "complete_data = complete_data[['Date', 'Name of State / UT', 'Latitude', 'Longitude', \n",
    "                               'Total Confirmed cases', 'Death', 'Cured/Discharged/Migrated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename state names\n",
    "complete_data['Name of State / UT'] = complete_data['Name of State / UT'].replace('Dadar Nagar Haveli', 'Dadra and Nagar Haveli and Daman and Diu')\n",
    "complete_data['Name of State / UT'] = complete_data['Name of State / UT'].replace('Daman & Diu', 'Dadra and Nagar Haveli and Daman and Diu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New cases\n",
    "# =========\n",
    "\n",
    "# temp dataset\n",
    "temp = complete_data.groupby(['Name of State / UT', 'Date', ])['Total Confirmed cases', 'Death', 'Cured/Discharged/Migrated']\n",
    "temp = temp.sum().diff().reset_index()\n",
    "\n",
    "mask = temp['Name of State / UT'] != temp['Name of State / UT'].shift(1)\n",
    "\n",
    "temp.loc[mask, 'Total Confirmed cases'] = np.nan\n",
    "temp.loc[mask, 'Death'] = np.nan\n",
    "temp.loc[mask, 'Cured/Discharged/Migrated'] = np.nan\n",
    "\n",
    "temp = temp[['Date', 'Name of State / UT', 'Total Confirmed cases', 'Death', 'Cured/Discharged/Migrated']]\n",
    "temp.columns = ['Date', 'Name of State / UT', 'New cases', 'New deaths', 'New recovered']\n",
    "\n",
    "# merging new values\n",
    "complete_data = pd.merge(complete_data, temp, on=['Name of State / UT', 'Date'])\n",
    "\n",
    "# filling na with 0\n",
    "complete_data = complete_data.fillna(0)\n",
    "\n",
    "# fixing data types\n",
    "cols = ['New cases', 'New deaths', 'New recovered']\n",
    "complete_data[cols] = complete_data[cols].astype('int')\n",
    "\n",
    "# remove negative values\n",
    "complete_data['New cases'] = complete_data['New cases'].apply(lambda x: 0 if x<0 else x)\n",
    "\n",
    "# final data\n",
    "complete_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random rows\n",
    "complete_data.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete data info\n",
    "complete_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save as .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data in a csv file\n",
    "complete_data.to_csv('complete.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete_data.groupby('Date').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete_data.sort_values('Death', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data[complete_data['Date']==max(complete_data['Date'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
